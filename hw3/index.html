<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: Rachel Hu, Philip Ye</div>

		<br>

		Link to webpage:  <a href="https://cal-cs184-student.github.io/hw-webpages-skibidirizz/hw3/index.html">https://cal-cs184-student.github.io/hw-webpages-skibidirizz/hw3/index.html</a>
		<br>
		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw3-jabroni-boi">https://github.com/cal-cs184-student/sp25-hw3-jabroni-boi</a>
		
		<figure>
			<img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
			<figcaption>Cornell Boxes with Bunnies</figcaption>
		</figure>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		Give a high-level overview of what you implemented in this homework. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the homework.

		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		<h4>Ray Generation Walkthrough</h4>
		<p>A camera captures the world into a 2D image, or "image space." Ray generation is essentially a way to estimate/recover the original real-world coordinates of a given point in this image space.</p>
		<p>The first step is to convert image space coordinates, (x, y), into camera space coordinates, (x, y, z). This is essentially done by fixing a Z value in camera space, then shifting and scaling the image (x, y) coordinates into their corresponding camera space coordinates.
			The z dimension here is intuitively the direction that the camera is looking at, called the viewing direction. We fix Z so as to put all image space coordinates in a plane in 3D.</p>
		<p>The ray from our camera (the origin in camera space) to this calculated location on the camera plane, is our desired camera space ray.</p>
		<p>Then, we use the camera-to-world conversion matrix to convert the camera space ray into world space. This can be thought of as a change of basis conversion. The new origin of the ray is therefore the camera's position in world space.</p>
		<p>Anything beyond a certain threshold set by min_t and max_t are considered out of frame from the camera's viewpoint. We also normalize the world space vector so as to keep consistent calculations across different rays and directions.</p>
		<p>We can then use this calculation to determine many things. For example, we used this, alongside Monte Carlo Integration, to estimate the radiance in this ray direction.</p>
		
		<h4>Primitive Intersection Walkthrough</h4>
		<p>You have a ray, and a primitive object, such as a triangle or sphere, and you want to check if and where they intersect. You can achieve this simply by setting the equations of these objects equal to each other to see if there exists a point at which they are equal. With rays specifically, this means calculating the t in the ray equation where it intersects the primitive object, and checking if the t-value obtained is valid or not.</p>
		<p>t being valid essentially means its within our field of view. If the intersection point is beyond our t-bounds, we cannot see the object. Every time we get a new, valid t, we set our maximum t to that t value. This makes sense intuitively, becomes it essentially means "once our ray hits this object, we can't see any object behind it."</p>
		<p>Checking these intersection points is used to correctly render objects in front of others.</p>
		
		<h4>Triangle Intersection Algorithm</h4>
		<p>
			To check whether a ray intersection a triangle, we first checked if the ray intersected the plane the triangle was on, by deriving the plane equation from the triangle's coordinates, then setting these equations equal to each other to find the t ("time") at which the ray intersects the plane.
			If it did intersect, we used a 3D point-in-triangle test to determine if the intersection point between the ray and the plane, lied inside the triangle.
			For that, we checked whether or not the point was on the correct side of each edge of the triangle. If it were on the correct / same side of all three edges, it means it is inside the triangle.
		</p>
		<p>
			Later on, we used the Moller Trumbore algorithm to get barycentric coordinates for our intersection point within the triangle, which we then used to interpolate the surface normal at the intersection point. This surface normal has many use cases, in this case namely for shading and lighting.
		</p>
		<h4>Example Images</h4>
		<p>Here's a few examples of the result of implementing ray generation and primitive intersection algorithms:</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="CBempty.png" width="300px"/>
				  <figcaption>CBempty</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="CBspheres.png" width="300px"/>
				  <figcaption>CBspheres</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="banana.png" width="300px"/>
				  <figcaption>banana</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="building.png" width="300px"/>
				  <figcaption>building</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<!-- <p>Here is an example 2x2 gridlike structure using an HTML table. Each <b>tr</b> is a row and each <b>td</b> is a column in that row. You might find this useful for framing and showing your result images in an organized fashion.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr>
			</table>
		</div> -->
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>
			<p>
				In our BVH construction algorithm, we decided to recursively divide the list of primitives into a binary tree structure (per the spec), where each node contains a bounding box that encloses its child primitives. We'd like to organize the primitives spatially so that ray-primitive intersection tests can be performed efficiently, 
			by quickly culling (or "pruning") large sections of the scene that do not intersect the ray.
			</p>
			<p>
				We start out our algorithm with some given range of primitives (start to end) and checks whether the number of primitives is less than or equal to a user-specified max_leaf_size. If it happens to be so, we create a leaf node by storing that range of primitives and then return.
			However, if the number of primitives exceeds max_leaf_size, the algorithm must decide how to split the primitives into two subsets, and this is where our splitting heuristic comes in.
			</p>
			<p>
				
			</p>

		<h2>Part 3: Direct Illumination</h2>
		<p>
			In this part, we implemented 2 different types of direct lighting: direct lighting with uniform hemisphere sampling and direct lighting with importance sampling lights
		</p>

		<p>
			At a high level, Direct Lighting with <b>Uniform Hemisphere sampling</b> works by sampling directions uniformly over the hemisphere centered around the surface normal. We calculate the hit point of the ray using its origin and direction, as well 
			as the number of samples to use, and from here, we follow a couple of steps:
			<li>
				Sample a random direction using hemisphereSampler->get_sample()
			</li>
			<li>
				Transform said direction into our world coordinates, then we cast a shadow ray from the hit point in the sampled direction to check if it intersects with any object in the scene. 
				If it hits an object, we need to check whether that object emits light using bsdf->get_emission()	
			</li>
			<li>
				Evaluate the BSDF at the surface using the outgoing direction (w_out) and the sampled incoming direction
			</li>
			<li>
				From here, we just run the Monte Carlo algorithm and sum it up. We have f(p, wj -> wr), L(p, wj), cos(theta) and p(wj), so we can just plug it into our formula from Lecture 13!
			</li>
		</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<img src="mclol.png" width="300px"/>
		</div>
		

		<p>
			<b>Importance sampling</b> aims to improves the efficiency from uniform hemisphere sampling by sampling only directions that point toward actual lights in the scene. We use our knowledge about light sources to bias sampling toward more meaningful directions -> hence the name importance sampling!
		</p>
		<p>
			This time, we'll iterate through all the lights in the scene. If we have a delta light (point light), only sample one direction to the light. 
			If not, we'll have to sample ns_area_light times to better approximate the range of incoming directions.
		</p>
		<p>
			<li>
				For each light, we'll call light->sample_light. This gives us radiance of the light from w_i, and it writes out the direction w_i, distance to the light, and the associated sampling pdf
			</li>
			<li>
				Discard "bad" lights (invalid pdfs, or "shadow rays". These can be tested by casting a shadow ray and checking for other intersections with blocking objects.)
			</li>
			<li>
				Now run the Monte Carlo algorithm similar to Uniform Sampling. For area lights, we need to average the L_out produced by all the samples.
			</li>
		</p>


		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="bunny_64_32.png" width="300px"/>
				  <figcaption>Hemisphere Lighting</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="bunny_64_32_imp_sampling.png" width="300px"/>
				  <figcaption>Importance Sampling</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="dragon_screenshot_3-29_2-45-58.png" width="300px"/>
				  <figcaption>Hemisphere Lighting</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="dragon_screenshot_3-29_2-48-45.png" width="300px"/>
				  <figcaption>Importance Sampling</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		
		
		<h2>Part 4: Global Illumination</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Part 5: Adaptive Sampling</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>(Optional) Part 6: Extra Credit Opportunities</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
		
		<h2>Additional Notes (please remove)</h2>
		<ul>
			<li>You can also add code if you'd like as so: <code>code code code</code></li>
			<li>If you'd like to add math equations, 
				<ul>
					<li>You can write inline equations like so: \( a^2 + b^2 = c^2 \)</li>
					<li>You can write display equations like so: \[ a^2 + b^2 = c^2 \]</li>
				</ul>
			</li>
		</ul>
		</div>
	</body>
</html>